{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "**Start reading [here](https://docs.python.org/3.6/howto/regex.html#regex-howto)**.\n",
    "\n",
    "[The Python 3.6 documentation](https://docs.python.org/3.6/library/re.html).\n",
    "\n",
    "[Doug Knox's introduction](https://programminghistorian.org/en/lessons/understanding-regular-expressions).  Examples are in Open Office, not Python, but it's worth reviewing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data\n",
    "\n",
    "Let's use the first 674 characters from Edwin Abbott's *Flatland* (I downloaded this data from Project Gutenberg and manually removed the PG header and footer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLATLAND\n",
      "\n",
      "\n",
      "\n",
      "PART 1\n",
      "\n",
      "THIS WORLD\n",
      "\n",
      "\n",
      "\n",
      "SECTION 1  Of the Nature of Flatland\n",
      "\n",
      "\n",
      "I call our world Flatland, not because we call it so, but to make its\n",
      "nature clearer to you, my happy readers, who are privileged to live in\n",
      "Space.\n",
      "\n",
      "Imagine a vast sheet of paper on which straight Lines, Triangles,\n",
      "Squares, Pentagons, Hexagons, and other figures, instead of remaining\n",
      "fixed in their places, move freely about, on or in the surface, but\n",
      "without the power of rising above or sinking below it, very much like\n",
      "shadows--only hard with luminous edges--and you will then have a pretty\n",
      "correct notion of my country and countrymen.  Alas, a few years ago, I\n",
      "should have said \"my universe:\"  \n"
     ]
    }
   ],
   "source": [
    "text = open('data/pg97_Abbott_Edwin_Flatland.txt').read()[1:673]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basics . . . sub and split\n",
    "\n",
    "sub, right from the doc:\n",
    "\n",
    "    re.sub(pattern, repl, string, count=0, flags=0)\n",
    "    \n",
    "which returns a string.\n",
    "    \n",
    "And split:\n",
    "\n",
    "    re.split(pattern, string, maxsplit=0, flags=0)\n",
    "    \n",
    "which returns a list of strings.\n",
    "\n",
    "There are several layers of complexity here:\n",
    "\n",
    "* The pattern can become quite complex; patterns are expressed using a **regular expression language**.\n",
    "* The string passed as an argument to re.sub and re.split can be expressed as a variable which contains a string, or as a function which returns a string; i.e., these things can nest.\n",
    "* The pattern can be precompiled to yield a regex object, which in turn has .sub and .split methods.\n",
    "\n",
    "Note, however, **most of the complexity here--and there's as much as you have appetite for--is in the pattern.**\n",
    "\n",
    "## Two simple examples.\n",
    "\n",
    "1.  Replace every occurence of one or more whitespace characters with a space.\n",
    "\n",
    "2.  Split the text at every point in which one or more whitespace characters occur.\n",
    "\n",
    "We express \"one or more whitespace characters\" with the the special character \"\\s\" and the repeating metacharacter \"+\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLATLAND PART 1 THIS WORLD SECTION 1 Of the Nature of Flatland I call our world Flatland, not because we call it so, but to make its nature clearer to you, my happy readers, who are privileged to live in Space. Imagine a vast sheet of paper on which straight Lines, Triangles, Squares, Pentagons, Hexagons, and other figures, instead of remaining fixed in their places, move freely about, on or in the surface, but without the power of rising above or sinking below it, very much like shadows--only hard with luminous edges--and you will then have a pretty correct notion of my country and countrymen. Alas, a few years ago, I should have said \"my universe:\" \n",
      "\n",
      "\n",
      "['FLATLAND', 'PART', '1', 'THIS', 'WORLD', 'SECTION', '1', 'Of', 'the', 'Nature', 'of', 'Flatland', 'I', 'call', 'our', 'world', 'Flatland,', 'not', 'because', 'we', 'call', 'it', 'so,', 'but', 'to', 'make', 'its', 'nature', 'clearer', 'to', 'you,', 'my', 'happy', 'readers,', 'who', 'are', 'privileged', 'to', 'live', 'in', 'Space.', 'Imagine', 'a', 'vast', 'sheet', 'of', 'paper', 'on', 'which', 'straight', 'Lines,', 'Triangles,', 'Squares,', 'Pentagons,', 'Hexagons,', 'and', 'other', 'figures,', 'instead', 'of', 'remaining', 'fixed', 'in', 'their', 'places,', 'move', 'freely', 'about,', 'on', 'or', 'in', 'the', 'surface,', 'but', 'without', 'the', 'power', 'of', 'rising', 'above', 'or', 'sinking', 'below', 'it,', 'very', 'much', 'like', 'shadows--only', 'hard', 'with', 'luminous', 'edges--and', 'you', 'will', 'then', 'have', 'a', 'pretty', 'correct', 'notion', 'of', 'my', 'country', 'and', 'countrymen.', 'Alas,', 'a', 'few', 'years', 'ago,', 'I', 'should', 'have', 'said', '\"my', 'universe:\"'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(re.sub('\\s+', ' ', text.strip()), '\\n\\n')\n",
    "\n",
    "print(re.split('\\s+', text.strip()), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A tour of \"patterns\"\n",
    "\n",
    "[Again, start reading here](https://docs.python.org/3.6/howto/regex.html#regex-howto).  More on syntax [here](https://docs.python.org/3.6/library/re.html#regular-expression-syntax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missouri PART 1 THIS WORLD SECTION 1 Of the Nature of Missouri I call our world Missouri, not because we call it so, but to make its nature clearer to you, my happy readers, who are privileged to live in Space. Imagine a vast sheet of paper on which straight Lines, Triangles, Squares, Pentagons, Hexagons, and other figures, instead of remaining fixed in their places, move freely about, on or in the surface, but without the power of rising above or sinking below it, very much like shadows--only hard with luminous edges--and you will then have a pretty correct notion of my country and countrymen. Alas, a few years ago, I should have said \"my universe:\" \n",
      "\n",
      "\n",
      "ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ \n",
      "\n",
      "\n",
      "FLATLANDPART1THISWORLDSECTION1OftheNatureofFlatlandIcallourworldFlatlandnotbecausewecallitsobuttomakeitsnatureclearertoyoumyhappyreaderswhoareprivilegedtoliveinSpaceImagineavastsheetofpaperonwhichstraightLinesTrianglesSquaresPentagonsHexagonsandotherfiguresinsteadofremainingfixedintheirplacesmovefreelyaboutonorinthesurfacebutwithoutthepowerofrisingaboveorsinkingbelowitverymuchlikeshadowsonlyhardwithluminousedgesandyouwillthenhaveaprettycorrectnotionofmycountryandcountrymenAlasafewyearsagoIshouldhavesaidmyuniverse \n",
      "\n",
      "\n",
      "FLATLAND PART 1 THIS WORLD SECTION 1 Of the Nature of Flatland I call our world Flatland not because we call it so but to make its nature clearer to you my happy readers who are privileged to live in Space Imagine a vast sheet of paper on which straight Lines Triangles Squares Pentagons Hexagons and other figures instead of remaining fixed in their places move freely about on or in the surface but without the power of rising above or sinking below it very much like shadowsonly hard with luminous edgesand you will then have a pretty correct notion of my country and countrymen Alas a few years ago I should have said my universe \n",
      "\n",
      "\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \n",
      "\n",
      "\n",
      "[!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~] \n",
      "\n",
      "\n",
      "FLATLAND PART 1 THIS WORLD SECTION 1 Of the Nature of Flatland I call our world Flatland  not because we call it so  but to make its nature clearer to you  my happy readers  who are privileged to live in Space  Imagine a vast sheet of paper on which straight Lines  Triangles  Squares  Pentagons  Hexagons  and other figures  instead of remaining fixed in their places  move freely about  on or in the surface  but without the power of rising above or sinking below it  very much like shadows  only hard with luminous edges  and you will then have a pretty correct notion of my country and countrymen  Alas  a few years ago  I should have said  my universe   \n",
      "\n",
      "\n",
      "FLATLAND PART 1 THIS WORLD SECTION 1 Of the Nature of Flatland I call our world Flatland not because we call it so but to make its nature clearer to you my happy readers who are privileged to live in Space Imagine a vast sheet of paper on which straight Lines Triangles Squares Pentagons Hexagons and other figures instead of remaining fixed in their places move freely about on or in the surface but without the power of rising above or sinking below it very much like shadows only hard with luminous edges and you will then have a pretty correct notion of my country and countrymen Alas a few years ago I should have said my universe  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "de_spaced_text = re.sub('\\s+', ' ', text.strip())\n",
    "\n",
    "#  We can match characters in a very simple fashion; note that I've added a flag\n",
    "#  so that the find \"half\" of the sub is case-insensitve.\n",
    "\n",
    "print(re.sub('Flatland', 'Missouri', de_spaced_text, flags=re.IGNORECASE), '\\n\\n')\n",
    "\n",
    "#  Usually, however, we want to think about characters in broad classes.  For example,\n",
    "#  we might want to change every character to a \"Z\" (useless in this instance, except\n",
    "#  to show that \".\" means \"any character\").\n",
    "\n",
    "print(re.sub('.', 'Z', de_spaced_text), '\\n\\n')\n",
    "\n",
    "#  Or, we might want to get rid of any punctuation (\"\\W\" means \"any non-alphanumeric character\"):\n",
    "\n",
    "print(re.sub('\\W', '', de_spaced_text), '\\n\\n')\n",
    "\n",
    "#  Not great, however; we'd like to keep the spaces (the brackets define a character class, which\n",
    "#  in this cases consists of the letters a through z, A through Z, 0 through 9, and whitespace; \"^\" \n",
    "#  immediately after the opening bracket means \"not\"; i.e, we're saying, \"match any character which\n",
    "#  is not in the word class a through z, etc).\n",
    "\n",
    "print(re.sub('[^a-zA-Z0-9\\s]', '', de_spaced_text), '\\n\\n')\n",
    "\n",
    "#  That's pretty good, but it doesn't handle the double hyphens.  If I build a character class that\n",
    "#  explicity declares all the punctuation, and replace punctuation with spaces, I get a pretty good\n",
    "#  result.  \n",
    "\n",
    "#  NOTE that the period in the character class acts as a literal, and not as the metacharacter\n",
    "#  meaning \"any character\".  This is the sort of thing that makes me grumble.\n",
    "\n",
    "import string\n",
    "\n",
    "print(string.punctuation, '\\n\\n')\n",
    "\n",
    "generated_expression = '[' + string.punctuation + ']'\n",
    "\n",
    "print(generated_expression, '\\n\\n')\n",
    "\n",
    "print(re.sub(generated_expression, ' ', de_spaced_text), '\\n\\n')\n",
    "\n",
    "#  And if I pass the sub results through a space-normalizing sub, I get a better result.\n",
    "\n",
    "print(re.sub('\\s+', ' ',\n",
    "                re.sub(generated_expression, ' ', de_spaced_text)), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns, plus a finditer, plus a little code . . . \n",
    "\n",
    "In this case, we can create a simple Key in Context display.  Three or four times.  Because I want to demo a kind of progressive elaboration of the pattern.  And to play with converting an iterator to a sequence.\n",
    "\n",
    "Note that here we introduce a find-type function which uses a regular expression to search a text for matching sequences.\n",
    "\n",
    "Python re module has at least three find-type functions: match (which checks for a match only at the beginning of the string), search (which checks anywhere).  [See the match vs search doc](https://docs.python.org/3.6/library/re.html#search-vs-match).  I tend to use re.finditer a lot, since it search the whole string and returns an iterator which provides information about all matches.\n",
    "\n",
    "The non-regex parts of this line:\n",
    "\n",
    "    for m in list(re.finditer('circle', de_spaced_text, re.IGNORECASE))[:10]:\n",
    "    \n",
    "may be a little complicated.  It's complicated becasue I only want the first 10 matches (\"m\" is my name for a match).  This:\n",
    "\n",
    "    for m in re.finditer('circle', de_spaced_text, re.IGNORECASE)[:10]:\n",
    "    \n",
    "won't work because re.finditer returns an iterator, which provides access to the items one-by-one, but which can't be accessed all at once, or sliced (\"\\[:10\\]\") like a sequence.  Casting the iterator to a list (\"list(  . . . )\" causes the iterator to realize/instantite all its matches; it's effectively like saying:\n",
    "\n",
    "    for m in [m for m in re.finditer('circle', de_spaced_text, re.IGNORECASE)][:10]:\n",
    "    \n",
    "i.e., like using a list comprehension to force the iterator into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it, look down upon it. It will appear a circle. But now, drawing back to the edge of t\n",
      " a Triangle, Square, Pentagon, Hexagon, Circle, what you will--a straight Line he look\n",
      "e figure cannot be distinguished from a circle, he is included in the Circular or Prie\n",
      "gth too much even for the wisdom of the Circles. But a wise ordinance of Nature has de\n",
      "of this Law of Nature, the Polygons and Circles are almost always able to stifle sedit\n",
      "l body of their brethren whom the Chief Circle keeps in pay for emergencies of this ki\n",
      " it has been found by the wisest of our Circles or Statesmen that the multiplication o\n",
      "sh promises by which the more judicious Circle can in a moment pacify his consort. The\n",
      "me of the Isosceles; and by many of our Circles the destructiveness of the Thinner Sex\n",
      "ursuits; and the cautious wisdom of the Circles has ensured safety at the cost of dome\n",
      "\n",
      "\n",
      "\n",
      "it, look down upon it. It will appear a circle. But now, drawing back to the edge of t\n",
      " a Triangle, Square, Pentagon, Hexagon, Circle, what you will--a straight Line he look\n",
      "e figure cannot be distinguished from a circle, he is included in the Circular or Prie\n",
      "gth too much even for the wisdom of the Circles. But a wise ordinance of Nature has de\n",
      "of this Law of Nature, the Polygons and Circles are almost always able to stifle sedit\n",
      "l body of their brethren whom the Chief Circle keeps in pay for emergencies of this ki\n",
      " it has been found by the wisest of our Circles or Statesmen that the multiplication o\n",
      "sh promises by which the more judicious Circle can in a moment pacify his consort. The\n",
      "me of the Isosceles; and by many of our Circles the destructiveness of the Thinner Sex\n",
      "ursuits; and the cautious wisdom of the Circles has ensured safety at the cost of dome\n",
      "\n",
      "\n",
      "\n",
      "it, look down upon it. It will appear a circle. But now, drawing back to the edge of th\n",
      " a Triangle, Square, Pentagon, Hexagon, Circle, what you will--a straight Line he looks\n",
      "e figure cannot be distinguished from a circle, he is included in the Circular or Pries\n",
      "l body of their brethren whom the Chief Circle keeps in pay for emergencies of this kin\n",
      "sh promises by which the more judicious Circle can in a moment pacify his consort. The \n",
      "emplate the complete circumference of a Circle in the happy region of the Three Dimensi\n",
      "gon, and, with some training, that of a Circle himself. A second method is therefore mo\n",
      "ble the famous story how an illustrious Circle, overcome by the artistic beauty of the \n",
      "same way, red being applied to that semicircle in which the eye and mouth formed the mi\n",
      "le point; while the other or hinder semicircle was to be coloured green. There was no l\n",
      "\n",
      "\n",
      "\n",
      " it, look down upon it. It will appear a circle. But now, drawing back to the edge of th\n",
      "e a Triangle, Square, Pentagon, Hexagon, Circle, what you will--a straight Line he looks\n",
      "he figure cannot be distinguished from a circle, he is included in the Circular or Pries\n",
      "ll body of their brethren whom the Chief Circle keeps in pay for emergencies of this kin\n",
      "ish promises by which the more judicious Circle can in a moment pacify his consort. The \n",
      "template the complete circumference of a Circle in the happy region of the Three Dimensi\n",
      "ygon, and, with some training, that of a Circle himself. A second method is therefore mo\n",
      "ible the famous story how an illustrious Circle, overcome by the artistic beauty of the \n",
      "el of state-craft--but from an Irregular Circle who, instead of being destroyed in his c\n",
      " some commands in the name of a priestly Circle; out of doors the striking combination o\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, string\n",
    "    \n",
    "text = open('data/pg97_Abbott_Edwin_Flatland.txt').read()\n",
    "\n",
    "de_spaced_text = re.sub('\\s+', ' ', text.strip())\n",
    "\n",
    "for m in list(re.finditer('circle', de_spaced_text, re.IGNORECASE))[:10]:\n",
    "    \n",
    "    a = m.start() - 40\n",
    "    if a < 0:\n",
    "        a = 0\n",
    "    b = m.end() + 40\n",
    "    if b > len(de_spaced_text):\n",
    "        b = len(de_spaced_text)\n",
    "        \n",
    "    print(de_spaced_text[a: b])\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "for m in [m for m in re.finditer('circle', de_spaced_text, re.IGNORECASE)][:10]:\n",
    "    \n",
    "    a = m.start() - 40\n",
    "    if a < 0:\n",
    "        a = 0\n",
    "    b = m.end() + 40\n",
    "    if b > len(de_spaced_text):\n",
    "        b = len(de_spaced_text)\n",
    "        \n",
    "    print(de_spaced_text[a: b])\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "for m in list(re.finditer('circle[\\s' + string.punctuation + ']', de_spaced_text, re.IGNORECASE))[:10]:\n",
    "    \n",
    "    a = m.start() - 40\n",
    "    if a < 0:\n",
    "        a = 0\n",
    "    b = m.end() + 40\n",
    "    if b > len(de_spaced_text):\n",
    "        b = len(de_spaced_text)\n",
    "        \n",
    "    print(de_spaced_text[a: b])\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "for m in list(re.finditer('\\scircle[\\s' + string.punctuation + ']', de_spaced_text, re.IGNORECASE))[:10]:\n",
    "    \n",
    "    a = m.start() - 40\n",
    "    if a < 0:\n",
    "        a = 0\n",
    "    b = m.end() + 40\n",
    "    if b > len(de_spaced_text):\n",
    "        b = len(de_spaced_text)\n",
    "        \n",
    "    print(de_spaced_text[a: b])\n",
    "\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More \"regex + a little code\"\n",
    "\n",
    "Here, to get the 25 most common words in *Flatland*, \"most common\" meaning, \"except the stuff like 'and', 'the', 'a', etc.\"\n",
    "\n",
    "[nltk](https://www.nltk.org/) is more or less the standard way to start learning Natural Language Processing on Python, and there's [a standard book](https://www.nltk.org/book/) available [online](https://www.nltk.org/book/), which everyone has at least looked at one time or another.  The library has other NLTK books online; simply search nltk in [the library's website](https://library.wustl.edu/).\n",
    "\n",
    "[Counter](https://docs.python.org/3/library/collections.html#collections.Counter) is super useful, since we're likely to find ourselves constantly needing to count and order items in sequences.\n",
    "\n",
    "I find that this pattern\n",
    "\n",
    "     re.split('[^a-z]', text.strip().lower())\n",
    "     \n",
    "is one I use quite often; in effect, it converts a plain text file into a list of lower case words . . . it's a kind of quick-and-dirty [tokenization](https://www.techopedia.com/definition/13698/tokenization).  However, for a more rigorous approach, I always turn to a natural language processing library with more sophisticated rules.  Why?  Consider the word\n",
    "\n",
    "    quick-and-dirty\n",
    "    \n",
    "My regex approach yields \\[\"quick\", \"and\", \"dirty\"\\]; I would hope that a real NLP library would leave \"quick-and-dirty\" all together as one token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 3)\n",
      "('b', 3)\n",
      "('c', 3)\n",
      "('d', 2)\n",
      "('e', 2)\n",
      "\n",
      "\n",
      "\n",
      "a 3\n",
      "b 3\n",
      "c 3\n",
      "d 2\n",
      "e 2\n",
      "\n",
      "\n",
      "\n",
      "one 157\n",
      "would 114\n",
      "see 113\n",
      "line 95\n",
      "flatland 81\n",
      "two 80\n",
      "could 77\n",
      "three 77\n",
      "must 76\n",
      "even 72\n",
      "sides 63\n",
      "circle 62\n",
      "square 59\n",
      "every 59\n",
      "say 58\n",
      "sphere 58\n",
      "may 57\n",
      "space 56\n",
      "straight 55\n",
      "us 53\n",
      "women 53\n",
      "yet 50\n",
      "woman 50\n",
      "said 49\n",
      "point 49\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = set(stopwords.words('english'))\n",
    "    \n",
    "some_list = ['a', 'b', 'c', 'd', 'e', 'a', 'b', 'c', 'd', 'e', 'a', 'b', 'c']\n",
    "    \n",
    "for word in Counter(some_list).most_common():\n",
    "    print(word)\n",
    "\n",
    "print('\\n\\n')\n",
    "    \n",
    "for word, word_count in Counter(some_list).most_common():\n",
    "    print(word, word_count)\n",
    "\n",
    "print('\\n\\n')\n",
    "    \n",
    "text = open('data/pg97_Abbott_Edwin_Flatland.txt').read()\n",
    "\n",
    "for word, word_count in Counter([w for w in re.split('[^a-z]', text.strip().lower()) \n",
    "                                     if w > '' and w not in sw]).most_common(25):\n",
    "    print(word, word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "\n",
    "What happens if, instead of\n",
    "\n",
    "    '[^a-z]'\n",
    "    \n",
    "I used\n",
    "\n",
    "    '([^a-z])'\n",
    "   \n",
    "What character occurs 31,452 times?  3,489 times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  31452\n",
      "\n",
      " 3489\n",
      ", 2443\n",
      ". 1139\n",
      "- 662\n",
      "\" 541\n",
      "; 373\n",
      "one 157\n",
      "? 143\n",
      "' 124\n",
      "would 114\n",
      "see 113\n",
      "line 95\n",
      "flatland 81\n",
      "two 80\n",
      "( 78\n",
      ") 78\n",
      "could 77\n",
      "three 77\n",
      "must 76\n",
      "! 74\n",
      "even 72\n",
      ": 71\n",
      "sides 63\n",
      "circle 62\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "    \n",
    "text = open('data/pg97_Abbott_Edwin_Flatland.txt').read()\n",
    "\n",
    "for word, word_count in Counter([w for w in re.split('([^a-z])', text.strip().lower()) \n",
    "                                     if w > '' and w not in sw]).most_common(25):\n",
    "    print(word, word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
